[0m[[0m[0mdebug[0m] [0m[0m> Exec(collectAnalyses, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Processing event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/Projects/Flink-streaming/src/main/scala/Trying.scala","languageId":"scala","version":1,"text":"import org.apache.flink.api.common.eventtime.WatermarkStrategy\nimport org.apache.flink.api.common.serialization.SimpleStringSchema\nimport org.apache.flink.connector.kafka.source.KafkaSource\nimport org.apache.flink.connector.kafka.sink.KafkaRecordSerializationSchema\nimport org.apache.flink.connector.kafka.sink.KafkaSink\nimport org.apache.flink.streaming.connectors.cassandra.CassandraSink\nimport org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.streaming.connectors.cassandra.ClusterBuilder\nimport org.apache.flink.streaming.connectors.cassandra.CassandraSinkBase\n// import org.apache.flink.streaming.connectors.cassandra.CassandraSource\nimport com.datastax.driver.core.Cluster\n\n\nobject Trying extends App {\n  val env = StreamExecutionEnvironment.getExecutionEnvironment\n  val kafkaSource = KafkaSource.builder()\n  .setBootstrapServers(\"localhost:9092\")\n  .setTopics(\"flinkex\")\n  .setGroupId(\"flink-consumer-group\")\n  .setStartingOffsets(OffsetsInitializer.latest())\n  .setValueOnlyDeserializer(new SimpleStringSchema())\n  .build()\n  println(\"Checkpoint 1\")\n\n  val serializer = KafkaRecordSerializationSchema.builder()\n  .setValueSerializationSchema(new SimpleStringSchema())\n  .setTopic(\"flinkout\")\n  .build()\n\n  val cassandraHost = \"localhost\"\n  val cassandraPort = 9042\n  val cassandraKeyspace = \"flink_db\"\n  val cassandraTable = \"teachers\"\n\n  println(\"Checkpoint 2\")\n  val stream = env.addSource(new CassandraSourceFunction)\n  println(\"Checkpoint 3\")\n  stream.print()\n  println(\"Checkpoint 4\")\n\n  // val clusterBuilder = Cluster.builder().addContactPoint(cassandraHost).withPort(cassandraPort)\n  // val cassandraInputFormat = new CassandraSource(cassandraHost, cassandraPort, cassandraKeyspace, cassandraTable, clusterBuilder)\n\n  val kafkaSink = KafkaSink.builder()\n  .setBootstrapServers(\"localhost:9092\")\n  .setRecordSerializer(serializer)\n  .build()\n  println(\"Checkpoint 5\")\n\n  val stream2 = env.fromSource(kafkaSource, WatermarkStrategy.noWatermarks(), \"Kafka Source\")\n  // stream.print()\n  // stream.sinkTo(kafkaSink)\n\n  println(\"Checkpoint 6\")\n  env.execute(\"Trying\")\n\n}\n"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / collectAnalyses[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0manalysis location (C:\Projects\Flink-streaming\target\scala-2.12\zinc\inc_compile_2.12.zip,true)[0m
[0m[[0m[32msuccess[0m] [0m[0mTotal time: 1 s, completed 25-Jul-2023, 2:04:08 AM[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Done event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mForcing garbage collection...[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled request received: shutdown: JsonRpcRequestMessage(2.0, â™¨1, shutdown, null})[0m
